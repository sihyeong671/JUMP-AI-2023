{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\BSH\\.virtualenvs\\신약개발-mImSxWNo\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "from optuna.pruners import HyperbandPruner\n",
    "\n",
    "import rdkit\n",
    "from rdkit.Chem import AllChem, rdFingerprintGenerator\n",
    "from rdkit import Chem, DataStructs\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, KFold\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import catboost as cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 777"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineer():\n",
    "  train_df = pd.read_csv(\"../data/train.csv\")\n",
    "  test_df = pd.read_csv(\"../data/test.csv\")\n",
    "  train_df = train_df.dropna()\n",
    "  test_df[\"AlogP\"] = np.where(pd.isna(test_df[\"AlogP\"]), test_df[\"LogD\"], test_df[\"AlogP\"])\n",
    "  \n",
    "  train_df[\"mol\"] = train_df[\"SMILES\"].apply(lambda x: Chem.MolFromSmiles(x))\n",
    "  test_df[\"mol\"] = test_df[\"SMILES\"].apply(lambda x: Chem.MolFromSmiles(x))\n",
    "  \n",
    "  train_df['mol'] = train_df['mol'].apply(lambda x: Chem.AddHs(x))\n",
    "  train_df['num_of_atoms'] = train_df['mol'].apply(lambda x: x.GetNumAtoms())\n",
    "  train_df['num_of_heavy_atoms'] = train_df['mol'].apply(lambda x: x.GetNumHeavyAtoms())\n",
    "  \n",
    "  test_df['mol'] = test_df['mol'].apply(lambda x: Chem.AddHs(x))\n",
    "  test_df['num_of_atoms'] = test_df['mol'].apply(lambda x: x.GetNumAtoms())\n",
    "  test_df['num_of_heavy_atoms'] = test_df['mol'].apply(lambda x: x.GetNumHeavyAtoms())\n",
    "  \n",
    "  # 중복제거\n",
    "  def canonize(mol):\n",
    "    return Chem.MolToSmiles(Chem.MolFromSmiles(mol), isomericSmiles=True, canonical=True)\n",
    "\n",
    "  canon_smile = []\n",
    "  for molecule in train_df['SMILES']:\n",
    "    canon_smile.append(canonize(molecule))\n",
    "  \n",
    "  train_df['canon_smiles'] = canon_smile\n",
    "  \n",
    "  ind = train_df.index[train_df['canon_smiles'].duplicated()]\n",
    "  train_df = train_df.drop(ind)\n",
    "  \n",
    "  train_df.drop(columns=[\"id\", \"SMILES\"], inplace=True)\n",
    "  test_df.drop(columns=[\"id\", \"SMILES\"], inplace=True)\n",
    "  \n",
    "  fmgen = rdFingerprintGenerator.GetMorganGenerator()\n",
    "  train_fps = train_df[\"mol\"].apply(lambda x: fmgen.GetFingerprintAsNumPy(x))\n",
    "  train_fps = np.stack(train_fps)\n",
    "  test_fps = test_df[\"mol\"].apply(lambda x: fmgen.GetFingerprintAsNumPy(x))\n",
    "  test_fps = np.stack(test_fps)\n",
    "  \n",
    "  origin_train_features = train_df[[\"AlogP\", \"Molecular_Weight\", \"Num_H_Acceptors\", \"Num_H_Donors\", \"Num_RotatableBonds\", \"LogD\", \"Molecular_PolarSurfaceArea\", \"num_of_atoms\", \"num_of_heavy_atoms\"]].values\n",
    "  origin_test_features = test_df[[\"AlogP\", \"Molecular_Weight\", \"Num_H_Acceptors\", \"Num_H_Donors\", \"Num_RotatableBonds\", \"LogD\", \"Molecular_PolarSurfaceArea\", \"num_of_atoms\", \"num_of_heavy_atoms\"]].values\n",
    "  \n",
    "  train_features = np.append(origin_train_features, train_fps, axis=1)\n",
    "  test_features = np.append(origin_test_features, test_fps, axis=1)\n",
    "  target = train_df[\"HLM\"].values\n",
    "  \n",
    "  return train_features, target, test_features\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n",
      "3496\n",
      "3469\n"
     ]
    }
   ],
   "source": [
    "train_x, train_y, test_x = feature_engineer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(param):\n",
    "  return cat.CatBoostRegressor(\n",
    "    random_state=RANDOM_SEED,\n",
    "    verbose=False,\n",
    "    **param\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(param, X, y, X_test, trial=None):\n",
    "    skf = KFold(n_splits=5, shuffle=True, random_state=RANDOM_SEED)\n",
    "\n",
    "    val_scores = []\n",
    "    y_tests = []\n",
    "    models = []\n",
    "\n",
    "    for idx, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n",
    "\n",
    "        X_train, y_train = X[train_idx], y[train_idx]\n",
    "        X_val, y_val = X[val_idx], y[val_idx]\n",
    "\n",
    "        model = create_model(param)\n",
    "        model.fit(X_train, y_train, eval_set=[(X_train, y_train), (X_val, y_val)], early_stopping_rounds=50, verbose=500)\n",
    "\n",
    "        y_hat_val = model.predict(X_val)\n",
    "        score = mean_squared_error(y_val, y_hat_val, squared=True)\n",
    "        val_scores.append(score)\n",
    "        print(f'Fold: {idx+1}/5 score = {score:.5f}')\n",
    "\n",
    "        y_tests.append(model.predict(X_test))\n",
    "        models.append(model)\n",
    "\n",
    "        if trial:\n",
    "            trial.report(score, idx)\n",
    "\n",
    "            if trial.should_prune():\n",
    "                raise optuna.TrialPruned()\n",
    "\n",
    "    return val_scores, y_tests, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_cat(trial):\n",
    "    param = {\n",
    "        \"iterations\": trial.suggest_int(\"iterations\", 2000, 20000),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.001, 0.3),\n",
    "        \"depth\": trial.suggest_int(\"depth\", 1, 10),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.1, 1.0),\n",
    "        \"min_data_in_leaf\": trial.suggest_int(\"min_data_in_leaf\", 10, 100),\n",
    "        \"colsample_bylevel\": trial.suggest_float(\"colsample_bylevel\", 0.05, 1.0),\n",
    "    }\n",
    "\n",
    "    val_scores, y_tests, models = train_model(param, train_x, train_y, test_x, trial)\n",
    "\n",
    "    return sum(val_scores) / len(val_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(\n",
    "    sampler=TPESampler(seed=RANDOM_SEED),\n",
    "    direction='minimize',\n",
    "    study_name='cat_tuning',\n",
    "    pruner=HyperbandPruner(\n",
    "        min_resource=1, max_resource=8, reduction_factor=3\n",
    "    ),\n",
    ")\n",
    "\n",
    "study.optimize(objective_cat, n_trials=70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial = study.best_trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(trial.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_param = {\n",
    "  'iterations': 5384,\n",
    "  'learning_rate': 0.016291040637706457,\n",
    "  'depth': 10,\n",
    "  'subsample': 0.9609604742509466,\n",
    "  'min_data_in_leaf': 96,\n",
    "  'colsample_bylevel': 0.36816810171615777\n",
    "}\n",
    "\n",
    "val_scores, y_tests, models = train_model(best_param, train_x, train_y, test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, model in enumerate(models):\n",
    "  model.save_model(f\"model/catboost_HLM_fold_{idx}.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.read_csv(\"../data/sample_submission.csv\")\n",
    "submit[\"HLM\"] = np.mean(y_tests, axis=0)\n",
    "submit.to_csv(\"catboost_optuna.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "신약개발-mImSxWNo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
